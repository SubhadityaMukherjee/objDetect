<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"videodetect","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rE_oVn61dneL","colab_type":"code","outputId":"d77a5379-2584-4536-f8c0-6a3af07e9a34","executionInfo":{"status":"ok","timestamp":1551878616014,"user_tz":-330,"elapsed":862,"user":{"displayName":"Subhaditya Mukherjee","photoUrl":"https://lh4.googleusercontent.com/-EOiGHS0mMdM/AAAAAAAAAAI/AAAAAAABc74/x8-bxB0NQpc/s64/photo.jpg","userId":"10930596869852951720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"FL__LV4Sgx9p","colab_type":"code","colab":{}},"cell_type":"code","source":["# ! cd /gdrive/Mçy\\ Drive && wget https://www.zamzar.com/download.php?uid=a35147e44bc5edc9b7d92cd8554f571-21155e64454ad190&targetId=pmVo4ovEoklaTBSA9AkKlg_I_I&fileID=p1d57csv2m164ous1ffd1qo8u034.mp4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XCAEMBdSeWud","colab_type":"code","colab":{}},"cell_type":"code","source":["import cv2\n","import numpy as np\n","import imutils\n","import os\n","import tensorflow as tf\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mEqYGbaE_lvs","colab_type":"code","colab":{}},"cell_type":"code","source":["# ! sudo apt install youtube-dl\n","\n","# ! youtube-dl -f 136 \"https://www.youtube.com/watch?v=5S-RLE2aMJU\" -o \"/gdrive/My Drive/Colab_ML/Object Recognition/car.mp4\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"IKZ2aKAAkfCP","colab_type":"code","colab":{}},"cell_type":"code","source":["def main_run(imagepath):\n","    config = '/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.cfg'\n","    weights = '/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.weights'\n","    classes = '/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.txt'\n","    net = ''\n","    classes = None\n","    f = open('/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.txt','r')\n","    classes = [line.strip() for line in f.readlines()]\n","    np.random.seed(42)\n","    COLORS = np.random.randint(0, 255, size=(len(classes), 3),\n","        dtype=\"uint8\")\n","    net = cv2.dnn.readNet(weights,config)\n","    ln = net.getLayerNames()\n","    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","    \n","    vs = cv2.VideoCapture(imagepath)\n","    writer = None\n","    (W, H) = (None, None)\n","\n","    try:\n","        prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n","            else cv2.CAP_PROP_FRAME_COUNT\n","        total = int(vs.get(prop))\n","        print(\"[INFO] {} total frames in video\".format(total))\n","\n","\n","    except:\n","        print(\"[INFO] could not determine # of frames in video\")\n","        print(\"[INFO] no approx. completion time can be provided\")\n","        total = -1\n","\n","    while True:\n","\t# read the next frame from the file\n","        (grabbed, frame) = vs.read()\n","\n","\n","        if not grabbed:\n","            break\n","\n","\n","        if W is None or H is None:\n","            (H, W) = frame.shape[:2]\n","\n","\n","        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n","\t\tswapRB=True, crop=False)\n","        net.setInput(blob)\n","        start = time.time()\n","        layerOutputs = net.forward(ln)\n","        end = time.time()\n","        \n","        boxes = []\n","        confidences = []\n","        classIDs = []\n","        \n","        for output in layerOutputs:\n","\n","            for detection in output:\n","                scores = detection[5:]\n","                classID = np.argmax(scores)\n","                confidence = scores[classID]\n","\n","                if confidence > 0.5:\n","\n","                    box = detection[0:4] * np.array([W, H, W, H])\n","                    (centerX, centerY, width, height) = box.astype(\"int\")\n","\n","                    x = int(centerX - (width / 2))\n","                    y = int(centerY - (height / 2))\n","\n","                    boxes.append([x, y, int(width), int(height)])\n","                    confidences.append(float(confidence))\n","                    classIDs.append(classID)\n","        #           \n","        idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,\n","\t\t0.4)\n","        \n","        if len(idxs) > 0:\n","            for i in idxs.flatten():\n","                (x, y) = (boxes[i][0], boxes[i][1])\n","                (w, h) = (boxes[i][2], boxes[i][3])\n","\n","                color = [int(c) for c in COLORS[classIDs[i]]]\n","                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n","                text = \"{}: {:.4f}\".format(classes[classIDs[i]],\n","                    confidences[i])\n","                cv2.putText(frame, text, (x, y - 5),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","                \n","        if writer is None:\n","            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","            writer = cv2.VideoWriter('/gdrive/My Drive/Colab_ML/Object Recognition/output.mp4', fourcc, 30,\n","                (frame.shape[1], frame.shape[0]), True)\n","\n","            if total > 0:\n","                elap = (end - start)\n","                print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n","                print(\"[INFO] estimated total time to finish: {:.4f}\".format(\n","                    elap * total/60))\n","\n","        writer.write(frame)\n","\n","    print(\"[INFO] cleaning up...\")\n","    writer.release()\n","    vs.release()\n","\n","    \n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"JHTFUD55OedR","colab":{}},"cell_type":"code","source":["with tf.device('/device:GPU:0'):\n","    main_run('/gdrive/My Drive/Colab_ML/Object Recognition/car.mp4')"],"execution_count":0,"outputs":[]}]}
=======
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "videodetect",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SubhadityaMukherjee/objDetect/blob/master/videodetect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rE_oVn61dneL",
        "colab_type": "code",
        "outputId": "4fdab575-eab0-4da8-d995-7926e69d00ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XCAEMBdSeWud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import imutils\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FL__LV4Sgx9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ! cd /gdrive/Mçy\\ Drive && wget https://www.zamzar.com/download.php?uid=a35147e44bc5edc9b7d92cd8554f571-21155e64454ad190&targetId=pmVo4ovEoklaTBSA9AkKlg_I_I&fileID=p1d57csv2m164ous1ffd1qo8u034.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mEqYGbaE_lvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ! sudo apt install youtube-dl\n",
        "# ! youtube-dl -f 160 \"https://www.youtube.com/watch?v=wslxspSwto0\" -o \"/gdrive/My Drive/Colab_ML/Object Recognition/car.mp4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_0bk9tkjRtr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "8_nnb-XxkCdA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_output_layers(net):\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        layer_names = net.getLayerNames()\n",
        "        output_layers = [layer_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
        "        return output_layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1KOzkxUMzZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "IKZ2aKAAkfCP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main_run(imagepath):\n",
        "    config = '/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.cfg'\n",
        "    weights = '/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.weights'\n",
        "    classes = '/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.txt'\n",
        "    net = ''\n",
        "    classes = None\n",
        "    f = open('/gdrive/My Drive/Colab_ML/Object Recognition/yolov3.txt','r')\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "    np.random.seed(42)\n",
        "    COLORS = np.random.randint(0, 255, size=(len(classes), 3),\n",
        "        dtype=\"uint8\")\n",
        "    net = cv2.dnn.readNet(weights,config)\n",
        "    ln = net.getLayerNames()\n",
        "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "    \n",
        "    vs = cv2.VideoCapture(imagepath)\n",
        "    writer = None\n",
        "    (W, H) = (None, None)\n",
        "\n",
        "    try:\n",
        "        prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
        "            else cv2.CAP_PROP_FRAME_COUNT\n",
        "        total = int(vs.get(prop))\n",
        "        print(\"[INFO] {} total frames in video\".format(total))\n",
        "\n",
        "\n",
        "    except:\n",
        "        print(\"[INFO] could not determine # of frames in video\")\n",
        "        print(\"[INFO] no approx. completion time can be provided\")\n",
        "        total = -1\n",
        "\n",
        "    while True:\n",
        "\t# read the next frame from the file\n",
        "        (grabbed, frame) = vs.read()\n",
        "\n",
        "\n",
        "        if not grabbed:\n",
        "            break\n",
        "\n",
        "\n",
        "        if W is None or H is None:\n",
        "            (H, W) = frame.shape[:2]\n",
        "\n",
        "\n",
        "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
        "\t\tswapRB=True, crop=False)\n",
        "        net.setInput(blob)\n",
        "        start = time.time()\n",
        "        layerOutputs = net.forward(ln)\n",
        "        end = time.time()\n",
        "        \n",
        "        boxes = []\n",
        "        confidences = []\n",
        "        classIDs = []\n",
        "        \n",
        "        for output in layerOutputs:\n",
        "\n",
        "            for detection in output:\n",
        "                scores = detection[5:]\n",
        "                classID = np.argmax(scores)\n",
        "                confidence = scores[classID]\n",
        "\n",
        "                if confidence > 0.5:\n",
        "\n",
        "                    box = detection[0:4] * np.array([W, H, W, H])\n",
        "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "                    x = int(centerX - (width / 2))\n",
        "                    y = int(centerY - (height / 2))\n",
        "\n",
        "                    boxes.append([x, y, int(width), int(height)])\n",
        "                    confidences.append(float(confidence))\n",
        "                    classIDs.append(classID)\n",
        "        #           \n",
        "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,\n",
        "\t\t0.4)\n",
        "        \n",
        "        if len(idxs) > 0:\n",
        "            for i in idxs.flatten():\n",
        "                (x, y) = (boxes[i][0], boxes[i][1])\n",
        "                (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "                color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "                text = \"{}: {:.4f}\".format(classes[classIDs[i]],\n",
        "                    confidences[i])\n",
        "                cv2.putText(frame, text, (x, y - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "                \n",
        "        if writer is None:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "            writer = cv2.VideoWriter('/gdrive/My Drive/Colab_ML/Object Recognition/output.mp4', fourcc, 30,\n",
        "                (frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "            if total > 0:\n",
        "                elap = (end - start)\n",
        "                print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n",
        "                print(\"[INFO] estimated total time to finish: {:.4f}\".format(\n",
        "                    elap * total))\n",
        "\n",
        "        writer.write(frame)\n",
        "\n",
        "    print(\"[INFO] cleaning up...\")\n",
        "    writer.release()\n",
        "    vs.release()\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "fe6c83c4-c083-4bfc-bfc0-248a72b51b42",
        "id": "JHTFUD55OedR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "main_run('/gdrive/My Drive/Colab_ML/Object Recognition/car.mp4')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] 300 total frames in video\n",
            "[INFO] single frame took 1.1255 seconds\n",
            "[INFO] estimated total time to finish: 337.6415\n",
            "[INFO] cleaning up...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
>>>>>>> 3b41a0c20f63965950132c9aaee789d2df1b8a6b
